{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6f921f-2a41-4232-939c-b6965a222b6f",
   "metadata": {},
   "source": [
    "## Preprocess FS Jump3D\n",
    "- 2D data from DWposeDetector\n",
    "- 3D data from json file formatted to h36m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4cfe6-baa4-4899-b216-348cef799d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dwpose.scripts.dwpose import DWposeDetector\n",
    "from dwpose.scripts.tool import read_frames\n",
    "from PIL import Image\n",
    "import torch\n",
    "import warnings\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5148cf-a980-4cfc-aae2-27fd3a806b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a585367d-a15d-453d-91d5-646894b13b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_file: str) -> dict:\n",
    "    with open(json_file, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a31379-f5da-4880-99e4-dfd3a484cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_range = load_json(\"./ranges.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c3fa9e-ca57-45a2-bb57-e5d6a65762e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_l_8x8_300e_coco/yolox_l_8x8_300e_coco_20211126_140236-d3bd2b23.pth\n",
      "Loads checkpoint by http backend from path: https://huggingface.co/wanghaofan/dw-ll_ucoco_384/resolve/main/dw-ll_ucoco_384.pth\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "detector = DWposeDetector(\n",
    "    det_config=\"D:\\\\github\\\\skating-ai\\\\v3\\\\pose\\\\dwpose\\\\config\\\\yolox_l_8xb8-300e_coco.py\",\n",
    "    # det_ckpt = args.yolox_ckpt,\n",
    "    pose_config=\"D:\\\\github\\\\skating-ai\\\\v3\\\\pose\\\\dwpose\\\\config\\\\dwpose-l_384x288.py\",\n",
    "    # pose_ckpt = args.dwpose_ckpt,\n",
    "    keypoints_only=True,\n",
    ")\n",
    "detector = detector.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41acb3a3-4625-4af2-99f1-a4c11181dd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd185818-e98a-4e99-a578-1004cb08eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ceca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_person(frame, num_person):\n",
    "    yolo_results = yolo_model(frame, classes=[0], verbose=False, device=\"cpu\")\n",
    "    person_idx = -1\n",
    "    if len(yolo_results[0].boxes) > 0:\n",
    "        largest_area = 0\n",
    "        for i, box in enumerate(yolo_results[0].boxes):\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                person_idx = min(i, num_person - 1)\n",
    "    return person_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace973da-2162-437c-b774-cb1be86bfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate2d(video_path, detector):\n",
    "    path_parts = Path(video_path).parts\n",
    "    skater = path_parts[4].lower()\n",
    "    jump = Path(video_path).stem.lower()\n",
    "\n",
    "    range_key = f\"{skater}-{jump}\"\n",
    "    start = int(frame_range[range_key][\"start\"])\n",
    "    end = int(frame_range[range_key][\"end\"]) + 1\n",
    "\n",
    "    frames = read_frames(video_path)[start:end]\n",
    "\n",
    "    num_frames = len(frames)\n",
    "    kpts2d = []\n",
    "    score2d = []\n",
    "    kpts2d.reserve(num_frames) if hasattr(kpts2d, \"reserve\") else None\n",
    "    score2d.reserve(num_frames) if hasattr(score2d, \"reserve\") else None\n",
    "\n",
    "    person_idx = 0\n",
    "\n",
    "    for idx, frame in enumerate(frames):\n",
    "        pose = detector(frame)\n",
    "        candidate = pose[\"bodies\"][\"candidate\"]\n",
    "        subset = pose[\"bodies\"][\"subset\"]\n",
    "        num_person = subset.shape[0]\n",
    "\n",
    "        if num_person == 0:\n",
    "            break\n",
    "\n",
    "        num_joints = subset.shape[1]\n",
    "        keypoint = candidate.reshape(num_person, num_joints, 2)\n",
    "\n",
    "        if num_person == 1:\n",
    "            kpts2d.append(keypoint[0, 1:])\n",
    "            score2d.append(subset[0, 1:])\n",
    "            continue\n",
    "\n",
    "        if idx == 0:\n",
    "            person_idx = detect_person(frame, num_person)\n",
    "\n",
    "        if person_idx >= num_person:\n",
    "            person_idx = detect_person(frame, num_person)\n",
    "\n",
    "        kpts2d.append(keypoint[person_idx, 1:])\n",
    "        score2d.append(subset[person_idx, 1:])\n",
    "\n",
    "    kpts2d = np.array(kpts2d)\n",
    "    score2d = np.array(score2d)\n",
    "\n",
    "    keypoints = np.concatenate([kpts2d, score2d[..., np.newaxis]], axis=-1)\n",
    "\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f109a1-a6ca-4956-b523-8b8d1e62b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path):\n",
    "    \"\"\"Process a single video file\"\"\"\n",
    "    # try:\n",
    "    path_parts = Path(video_path).parts\n",
    "    skater = path_parts[-3].lower()\n",
    "    camera = path_parts[-2].lower()\n",
    "    filename = Path(video_path).stem.lower()\n",
    "    output_name = f\"{skater}_{camera}_{filename}_2D.npy\"\n",
    "\n",
    "    output_path = os.path.join(output_dir, output_name)\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        keypoints = estimate2d(video_path, detector)\n",
    "        np.save(output_path, keypoints)\n",
    "    # except Exception as e:\n",
    "    #    print(f\"{video_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc827a09-4851-4db3-bf0c-ae4a28f6695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = glob.glob(\"D:\\\\github\\\\FS-Jump3D\\\\data\\\\**\\\\*.mp4\", recursive=True)\n",
    "output_dir = \"D:\\\\github\\\\MotionAGFormer\\\\data\\\\keypoints\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598783df-9629-4af4-901e-038235750648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                                                                      | 0/3036 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import Lock\n",
    "from tqdm import tqdm\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "\n",
    "def locked_process_video(video_path):\n",
    "    with lock:\n",
    "        return process_video(video_path)\n",
    "\n",
    "\n",
    "# Usage\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = [executor.submit(locked_process_video, path) for path in video_paths]\n",
    "    results = [future.result() for future in tqdm(futures, desc=\"Processing\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cf62e-e0bb-455e-8741-2b49ca7d5104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56945e42-c8c6-43dd-bb0c-de69287ecfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09fd8ea-9dc9-44d0-aa1c-e50331b136bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
